---
layout: post
title:  "More is not always better"
date:   2026-01-06 11:13:00 -0500
tags: ai software thinking science
---

My college years were spent studying rocks. While earning a degree in Geology, I was occupied with courses in physics, chemistry, and mathematics. These foundational sciences provided the context to begin to understand larger systems like climate, glaciology, and hydrogeology. I learned to deconstruct and explain outcomes by reducing them to core principles informed by my understanding of foundational mathematics and science. Now, after centuries of scientific deconstruction, the biggest challenges we face often involve reconstructing complex systems from these simpler parts. As [Steven Strogatz](https://www.stevenstrogatz.com/) argues, many of our largest challenges now involve understanding complex nonlinear systems with [emergent](https://en.wikipedia.org/wiki/Emergence) behaviors rather than understanding just the simpler parts that constitute them.

|<a title="Geolina163, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File:Geological_hammer,_WikiProjekt_Landstreicher_Geotop_Eistobel_01_(cropped).jpg"><img width="512" alt="Geological hammer, WikiProjekt Landstreicher Geotop Eistobel 01 (cropped)" src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Geological_hammer%2C_WikiProjekt_Landstreicher_Geotop_Eistobel_01_%28cropped%29.jpg/512px-Geological_hammer%2C_WikiProjekt_Landstreicher_Geotop_Eistobel_01_%28cropped%29.jpg?20190424141741"></a>|
|:--:|
| *Geology in the field* |

Software systems can be complex, even when the constituent parts are simple. Just like in natural systems, behaviors can arise giving us surprising or potentially unwanted outcomes. One way to address these emergent behaviors is to focus on better testing and observability while developing for graceful failures since there's often no way to predict all possible failure modes. My personal favorite method, guided by my work in the space of cost modeling and network design, is to model and simulate. With our modern tools, we can generate more tests and simulations than ever before, giving us more opportunities to stress the systems we create. When testing and simulating, consider if what is being tested is a simple system (a unit test for a specific function) or a complex system (solution built with multiple interacting services).

All of this becomes hyper-relevant in the age of AI. The "Opaque Giants" that are the models we now interact with are too large to be understood by humans. While we understand how they are constructed, we cannot understand why certain words are output or certain features are detected. These models are enabled by including unimaginable amounts of data, and improving them has predominantly focused on adding more and more data, because, after all, more is better, right? [Yuval Harari](https://www.ynharari.com/), in his book _Nexus_ describes what he terms the "naive view of information". The naive view centers around a few core falsehoods: that information represents reality and that more information reveals more truth. The table below contrasts the naive view with what Harari claims to be a more accurate historically informed view.

| Perspective | The Naive View | Harari's View (The Historical View) |
| - | - | - |
Purpose | To represent reality accurately. | To create connections and maintain order. |
| Quantity |  More data leads to more wisdom. | More data often amplifies bias and misinformation. |
Function | A tool for enlightenment. | Often a tool for creating "intersubjective realities" (e.g., money, nations). |
| Truth | Truth is the natural outcome of information. | Truth is a rare, costly byproduct that requires effort to preserve. |

_*Table was generated by Google Gemini_

To me, there is a common thread connecting Strogatz' shift from simple linear to complex non-linear systems, Harari's naive view of information, and modern technology ecosystems. Our software systems and models now rely in massive amounts of data inputs (*_*especially* our LLM tools) and are decidedly non-linear in their behavior. We need to approach these systems differently than the simple functions of the past, acknowledging the flaws identified by the naive view of information and the realities of complex system interactions. We must acknowledge that more information doesn't inevitably lead to more truthful or desirable outcomes. Ten years ago, [Kevin Kelly](https://x.com/kevin2kelly/status/564936801207341056) identified that in an era of cheap answers, the questions would matter more than ever. That is the reality we live in now, let's make sure to ask good questions.
